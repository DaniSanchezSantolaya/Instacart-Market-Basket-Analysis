{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train dataframe and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_train = pd.read_csv('df_train.csv')\n",
    "with open(\"pickles/labels.pickle\", 'rb') as handle:\n",
    "    labels = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['order_id'] = df_train['order_id'].astype(np.int32)\n",
    "df_train['product_id'] = df_train['product_id'].astype(np.int32)\n",
    "df_train['user_total_orders'] = df_train['user_total_orders'].astype(np.int16)\n",
    "df_train['user_total_items'] = df_train['user_total_items'].astype(np.int16)\n",
    "df_train['total_distinct_items'] = df_train['total_distinct_items'].astype(np.int16)\n",
    "df_train['user_average_days_between_orders'] = df_train['user_average_days_between_orders'].astype(np.float32)\n",
    "df_train['user_average_basket'] = df_train['user_average_basket'].astype(np.float32)\n",
    "df_train['mean_hour_purchase'] = df_train['mean_hour_purchase'].astype(np.float32)\n",
    "df_train['median_hour_purchase'] = df_train['median_hour_purchase'].astype(np.float32)\n",
    "df_train['most_frequent_day'] = df_train['most_frequent_day'].astype(np.int8)\n",
    "df_train['n_orders_most_frequent_day'] = df_train['n_orders_most_frequent_day'].astype(np.int16)\n",
    "df_train['prop_orders_most_frequent_day'] = df_train['prop_orders_most_frequent_day'].astype(np.float32)\n",
    "df_train['dow_last_prior_purchase'] = df_train['dow_last_prior_purchase'].astype(np.int8)\n",
    "df_train['order_dow'] = df_train['order_dow'].astype(np.int8)\n",
    "df_train['order_hour_of_day'] = df_train['order_hour_of_day'].astype(np.int8)\n",
    "df_train['days_since_prior_order'] = df_train['days_since_prior_order'].astype(np.float32)\n",
    "df_train['days_since_ratio'] = df_train['days_since_ratio'].astype(np.float32)\n",
    "df_train['delta_hour_vs_average'] = df_train['delta_hour_vs_average'].astype(np.float32)\n",
    "df_train['same_day_most_common_day'] = df_train['same_day_most_common_day'].astype(np.bool_)\n",
    "df_train['same_day_last_order_day'] = df_train['same_day_last_order_day'].astype(np.bool_)\n",
    "df_train['current_day'] = df_train['current_day'].astype(np.int16)\n",
    "df_train['aisle_id'] = df_train['aisle_id'].astype(np.uint8)\n",
    "df_train['department_id'] = df_train['department_id'].astype(np.uint8)\n",
    "df_train['product_orders'] = df_train['product_orders'].astype(np.int32)\n",
    "df_train['product_reorders'] = df_train['product_reorders'].astype(np.float32)\n",
    "df_train['product_reorder_rate'] = df_train['product_reorder_rate'].astype(np.float32)\n",
    "df_train['prob_purchase'] = df_train['prob_purchase'].astype(np.float32)\n",
    "df_train['aisle_orders'] = df_train['aisle_orders'].astype(np.int32)\n",
    "df_train['aisle_reorders'] = df_train['aisle_reorders'].astype(np.int32)\n",
    "df_train['aisle_reorder_rate'] = df_train['aisle_reorder_rate'].astype(np.float32)\n",
    "df_train['aisle_prob_purchase'] = df_train['aisle_prob_purchase'].astype(np.float32)\n",
    "df_train['department_orders'] = df_train['department_orders'].astype(np.int32)\n",
    "df_train['department_reorders'] = df_train['department_orders'].astype(np.int32)\n",
    "df_train['department_reorder_rate'] = df_train['department_reorder_rate'].astype(np.float32)\n",
    "df_train['department_prob_purchase'] = df_train['department_prob_purchase'].astype(np.float32)\n",
    "df_train['UP_orders'] = df_train['UP_orders'].astype(np.int16)\n",
    "df_train['UP_orders_ratio'] = df_train['UP_orders_ratio'].astype(np.float32)\n",
    "df_train['UP_average_pos_in_cart'] = df_train['UP_average_pos_in_cart'].astype(np.float32)\n",
    "df_train['UP_reorder_rate'] = df_train['UP_reorder_rate'].astype(np.float32)\n",
    "df_train['UP_orders_since_last'] = df_train['UP_orders_since_last'].astype(np.int16)\n",
    "df_train['UP_delta_hour_vs_last'] = df_train['UP_delta_hour_vs_last'].astype(np.int8)\n",
    "df_train['UP_mean_freq_days_order'] = df_train['UP_mean_freq_days_order'].astype(np.float32)\n",
    "df_train['UP_median_freq_days_order'] = df_train['UP_median_freq_days_order'].astype(np.float32)\n",
    "df_train['UP_only_one_order'] = df_train['UP_only_one_order'].astype(np.bool_)\n",
    "df_train['UP_days_from_last_purchase'] = df_train['UP_days_from_last_purchase'].astype(np.int16)\n",
    "df_train['UP_difference_last_purchase_and_mean'] = df_train['UP_difference_last_purchase_and_mean'].astype(np.float32)\n",
    "df_train['UP_days_from_last_purchase_ratio'] = df_train['UP_days_from_last_purchase_ratio'].astype(np.float32)\n",
    "df_train['UP_mean_hours'] = df_train['UP_mean_hours'].astype(np.float32)\n",
    "df_train['UP_delta_hour_vs_average_hour'] = df_train['UP_delta_hour_vs_average_hour'].astype(np.float32)\n",
    "df_train['UP_std_hour'] = df_train['UP_std_hour'].astype(np.float32)\n",
    "df_train['UP_most_common_day_of_week'] = df_train['UP_most_common_day_of_week'].astype(np.int8)\n",
    "df_train['UP_occurences_most_common_day_of_week'] = df_train['UP_occurences_most_common_day_of_week'].astype(np.int8)\n",
    "df_train['UP_proportion_occurences_most_common_day_of_week'] = df_train['UP_proportion_occurences_most_common_day_of_week'].astype(np.float32)\n",
    "df_train['UP_same_day_most_common_day'] = df_train['UP_same_day_most_common_day'].astype(np.bool_)\n",
    "df_train['UP_day_of_week_last_order'] = df_train['UP_day_of_week_last_order'].astype(np.int8)\n",
    "df_train['UP_same_day_last_order'] = df_train['UP_same_day_last_order'].astype(np.bool_)\n",
    "\n",
    "df_train['times_candidate'] = df_train['times_candidate'].astype(np.int32)\n",
    "df_train['times_reordered'] = df_train['times_reordered'].astype(np.int32)\n",
    "df_train['times_candidate_next_order'] = df_train['times_candidate_next_order'].astype(np.int32)\n",
    "df_train['times_reordered_next_order'] = df_train['times_reordered_next_order'].astype(np.int32)\n",
    "df_train['prob_reordered_candidate'] = (df_train['times_reordered']/df_train['times_candidate']).astype(np.float32)\n",
    "df_train['prob_reordered_next_order'] = (df_train['times_reordered_next_order']/df_train['times_candidate_next_order']).astype(np.float32)\n",
    "\n",
    "\n",
    "df_train['UP_times_candidate'] = df_train['UP_times_candidate'].astype(np.int32)\n",
    "df_train['UP_times_reordered'] = df_train['UP_times_reordered'].astype(np.int32)\n",
    "df_train['UP_times_candidate_next_order'] = df_train['UP_times_candidate_next_order'].astype(np.int32)\n",
    "df_train['UP_times_reordered_next_order'] = df_train['UP_times_reordered_next_order'].astype(np.int32)\n",
    "df_train['UP_prob_reordered_candidate'] = (df_train['UP_times_reordered']/df_train['UP_times_candidate']).astype(np.float32)\n",
    "df_train['UP_prob_reordered_next_order'] = (df_train['UP_times_reordered_next_order']/df_train['UP_times_candidate_next_order']).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                            int64\n",
       "order_id                                              int32\n",
       "product_id                                            int32\n",
       "user_total_orders                                     int16\n",
       "user_total_items                                      int16\n",
       "total_distinct_items                                  int16\n",
       "user_average_days_between_orders                    float32\n",
       "user_average_basket                                 float32\n",
       "mean_hour_purchase                                  float32\n",
       "median_hour_purchase                                float32\n",
       "most_frequent_day                                      int8\n",
       "n_orders_most_frequent_day                            int16\n",
       "prop_orders_most_frequent_day                       float32\n",
       "dow_last_prior_purchase                                int8\n",
       "order_dow                                              int8\n",
       "order_hour_of_day                                      int8\n",
       "days_since_prior_order                              float32\n",
       "days_since_ratio                                    float32\n",
       "delta_hour_vs_average                               float32\n",
       "same_day_most_common_day                               bool\n",
       "same_day_last_order_day                                bool\n",
       "current_day                                           int16\n",
       "aisle_id                                              uint8\n",
       "department_id                                         uint8\n",
       "product_orders                                        int32\n",
       "product_reorders                                    float32\n",
       "product_reorder_rate                                float32\n",
       "prob_purchase                                       float32\n",
       "times_candidate                                       int32\n",
       "times_reordered                                       int32\n",
       "                                                     ...   \n",
       "department_prob_purchase                            float32\n",
       "UP_orders                                             int16\n",
       "UP_orders_ratio                                     float32\n",
       "UP_average_pos_in_cart                              float32\n",
       "UP_reorder_rate                                     float32\n",
       "UP_orders_since_last                                  int16\n",
       "UP_delta_hour_vs_last                                  int8\n",
       "UP_mean_freq_days_order                             float32\n",
       "UP_median_freq_days_order                           float32\n",
       "UP_only_one_order                                      bool\n",
       "UP_days_from_last_purchase                            int16\n",
       "UP_difference_last_purchase_and_mean                float32\n",
       "UP_days_from_last_purchase_ratio                    float32\n",
       "UP_mean_hours                                       float32\n",
       "UP_delta_hour_vs_average_hour                       float32\n",
       "UP_std_hour                                         float32\n",
       "UP_most_common_day_of_week                             int8\n",
       "UP_occurences_most_common_day_of_week                  int8\n",
       "UP_proportion_occurences_most_common_day_of_week    float32\n",
       "UP_same_day_most_common_day                            bool\n",
       "UP_day_of_week_last_order                              int8\n",
       "UP_same_day_last_order                                 bool\n",
       "UP_times_candidate                                    int32\n",
       "UP_times_reordered                                    int32\n",
       "UP_times_candidate_next_order                         int32\n",
       "UP_times_reordered_next_order                         int32\n",
       "prob_reordered_candidate                            float32\n",
       "prob_reordered_next_order                           float32\n",
       "UP_prob_reordered_candidate                         float32\n",
       "UP_prob_reordered_next_order                        float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a validation set to tune the threshold later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation  import train_test_split\n",
    "df_train['labels'] = labels\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.075)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_to_use = ['user_total_orders', 'user_total_items', 'total_distinct_items',\n",
    "       'user_average_days_between_orders', 'user_average_basket',\n",
    "       'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n",
    "       'aisle_id', \n",
    "        'department_id', \n",
    "        'product_orders', 'product_reorders',\n",
    "       'product_reorder_rate', 'UP_orders', 'UP_orders_ratio',\n",
    "       'UP_average_pos_in_cart', 'UP_reorder_rate', 'UP_orders_since_last',\n",
    "       'UP_delta_hour_vs_last',\n",
    "       'n_orders_most_frequent_day', 'prop_orders_most_frequent_day',  # NEW user features\n",
    "       'same_day_most_common_day', 'same_day_last_order_day', # NEW order feautres (order-user)\n",
    "       'prob_purchase',\n",
    "       'UP_days_from_last_purchase', 'UP_mean_freq_days_order', 'UP_median_freq_days_order',\n",
    "       'UP_difference_last_purchase_and_mean', 'UP_mean_hours', 'UP_delta_hour_vs_average_hour',\n",
    "       'UP_std_hour', 'UP_occurences_most_common_day_of_week', 'UP_proportion_occurences_most_common_day_of_week',\n",
    "       'UP_same_day_most_common_day', 'UP_same_day_last_order', \n",
    "       'mean_hour_purchase', \n",
    "       'n_orders_most_frequent_day', 'prop_orders_most_frequent_day',\n",
    "       'delta_hour_vs_average', \n",
    "       'same_day_most_common_day', 'same_day_last_order_day',\n",
    "        'UP_only_one_order',\n",
    "        #'aisle_orders', 'aisle_reorders', 'aisle_reorder_rate', 'aisle_prob_purchase',\n",
    "        #'department_orders', 'department_reorders', 'department_reorder_rate', 'department_prob_purchase'\n",
    "        'times_candidate', 'times_reordered', 'times_candidate_next_order', 'times_reordered_next_order', \n",
    "        'prob_reordered_candidate', 'prob_reordered_next_order',\n",
    "        'UP_times_candidate', 'UP_times_reordered', 'UP_times_candidate_next_order', 'UP_times_reordered_next_order',\n",
    "        'UP_prob_reordered_candidate', 'UP_prob_reordered_next_order',\n",
    "        'UP_most_common_day_of_week', 'order_dow'\n",
    "           ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formating for lgb\n"
     ]
    }
   ],
   "source": [
    "print('formating for lgb')\n",
    "d_train = lgb.Dataset(df_train[f_to_use],\n",
    "                      label=df_train['labels'].values,\n",
    "                      categorical_feature=['aisle_id', 'department_id', 'UP_most_common_day_of_week', 'order_dow']) #'same_day_most_common_day', 'same_day_last_order_day', 'UP_same_day_most_common_day', 'UP_same_day_last_order', 'UP_only_one_order'])  # , 'order_hour_of_day', 'dow'\n",
    "del df_train\n",
    "d_val = lgb.Dataset(df_val[f_to_use],\n",
    "                      label=df_val['labels'].values,\n",
    "                      categorical_feature=['aisle_id', 'department_id', 'UP_most_common_day_of_week', 'order_dow'])# 'same_day_most_common_day', 'same_day_last_order_day', 'UP_same_day_most_common_day', 'UP_same_day_last_order', 'UP_only_one_order'], free_raw_data=True)  # , 'order_hour_of_day', 'dow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple training - Use it if we are not doing cross validation\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 96,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 30\n",
    "\n",
    "print('light GBM train :-)')\n",
    "bst = lgb.train(params=params, train_set=d_train, num_boost_round=ROUNDS, valid_sets=d_val, verbose_eval=10)\n",
    "#lgb.plot_importance(bst, figsize=(9,20))\n",
    "#del d_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(bst.eval(d_train, name='train'))\n",
    "print(bst.eval(d_val, name='valodat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light GBM train with learning rate 0.15, num leaves 106 and 120: \n"
     ]
    }
   ],
   "source": [
    "# Train with Cross validation\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 96,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 1000\n",
    "\n",
    "l_learning_rate= [0.15, 0.1, 0.05]\n",
    "l_num_leaves = [106, 96]\n",
    "l_min_data_in_leaf = [120, 110, 100]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for learning_rate in l_learning_rate:\n",
    "    for num_leaves in l_num_leaves:\n",
    "        for min_data_in_leaf in l_min_data_in_leaf:\n",
    "            params['learning_rate'] = learning_rate\n",
    "            params['num_leaves'] = num_leaves\n",
    "            params['min_data_in_leaf'] = min_data_in_leaf\n",
    "\n",
    "            print('light GBM train with learning rate ' + str(learning_rate) + ', num leaves ' + str(num_leaves) + ' and ' + str(min_data_in_leaf) + ': ')\n",
    "            results[str(learning_rate) + str(num_leaves) + str(min_data_in_leaf)] = lgb.cv(params=params, train_set=d_train, num_boost_round=ROUNDS, nfold=5,\n",
    "                         metrics=['binary_logloss', 'auc'], early_stopping_rounds=5, verbose_eval=50, seed=17)\n",
    "#lgb.plot_importance(bst, figsize=(9,20))\n",
    "#del d_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light GBM train :-)\n",
      "Train until valid scores didn't improve in 5 rounds.\n",
      "[20]\tvalid_0's binary_logloss: 0.349242\n",
      "[40]\tvalid_0's binary_logloss: 0.271035\n",
      "[60]\tvalid_0's binary_logloss: 0.251065\n",
      "[80]\tvalid_0's binary_logloss: 0.245967\n",
      "[100]\tvalid_0's binary_logloss: 0.244454\n",
      "[120]\tvalid_0's binary_logloss: 0.243762\n",
      "[140]\tvalid_0's binary_logloss: 0.24333\n",
      "[160]\tvalid_0's binary_logloss: 0.243031\n",
      "[180]\tvalid_0's binary_logloss: 0.242781\n",
      "[200]\tvalid_0's binary_logloss: 0.242551\n",
      "[220]\tvalid_0's binary_logloss: 0.242348\n",
      "[240]\tvalid_0's binary_logloss: 0.242198\n",
      "[260]\tvalid_0's binary_logloss: 0.242051\n",
      "[280]\tvalid_0's binary_logloss: 0.241928\n",
      "[300]\tvalid_0's binary_logloss: 0.241809\n",
      "[320]\tvalid_0's binary_logloss: 0.241712\n",
      "[340]\tvalid_0's binary_logloss: 0.241624\n",
      "[360]\tvalid_0's binary_logloss: 0.241535\n",
      "[380]\tvalid_0's binary_logloss: 0.241477\n",
      "[400]\tvalid_0's binary_logloss: 0.241395\n",
      "[420]\tvalid_0's binary_logloss: 0.241331\n",
      "[440]\tvalid_0's binary_logloss: 0.241266\n",
      "[460]\tvalid_0's binary_logloss: 0.24121\n",
      "[480]\tvalid_0's binary_logloss: 0.241178\n",
      "[500]\tvalid_0's binary_logloss: 0.241121\n",
      "[520]\tvalid_0's binary_logloss: 0.241074\n",
      "[540]\tvalid_0's binary_logloss: 0.241038\n",
      "Early stopping, best iteration is:\n",
      "[536]\tvalid_0's binary_logloss: 0.241037\n",
      "[('train', 'binary_logloss', 0.23829484145679369, False)]\n",
      "[('valodat', 'binary_logloss', 0.24103875589951707, False)]\n"
     ]
    }
   ],
   "source": [
    "# Train the single model with the selected parameters, and test with evaluation set\n",
    "\n",
    "final_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'}, #'auc'\n",
    "    'num_leaves': 96,\n",
    "    'min_data_in_leaf': 120,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "final_ROUNDS = 1000\n",
    "\n",
    "print('light GBM train :-)')\n",
    "bst = lgb.train(params=final_params, train_set=d_train, num_boost_round=final_ROUNDS, valid_sets=d_val, early_stopping_rounds=5, verbose_eval=20)\n",
    "print(bst.eval(d_train, name='train'))\n",
    "print(bst.eval(d_val, name='valodat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst.save_model('model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_distinct_items: 3239\n",
      "days_since_ratio: 3062\n",
      "UP_days_from_last_purchase: 2953\n",
      "user_average_basket: 2733\n",
      "user_total_items: 2332\n",
      "prob_reordered_next_order: 2288\n",
      "delta_hour_vs_average: 2032\n",
      "user_average_days_between_orders: 1940\n",
      "product_reorder_rate: 1874\n",
      "mean_hour_purchase: 1623\n",
      "days_since_prior_order: 1551\n",
      "UP_difference_last_purchase_and_mean: 1504\n",
      "UP_orders_since_last: 1368\n",
      "prop_orders_most_frequent_day: 1338\n",
      "UP_orders_ratio: 1273\n",
      "prob_reordered_candidate: 1204\n",
      "order_hour_of_day: 1047\n",
      "UP_mean_freq_days_order: 913\n",
      "UP_mean_hours: 909\n",
      "UP_average_pos_in_cart: 893\n",
      "UP_prob_reordered_candidate: 878\n",
      "product_orders: 873\n",
      "user_total_orders: 854\n",
      "order_dow: 833\n",
      "UP_delta_hour_vs_last: 831\n",
      "UP_delta_hour_vs_average_hour: 787\n",
      "aisle_id: 754\n",
      "product_reorders: 747\n",
      "UP_median_freq_days_order: 724\n",
      "UP_times_candidate: 709\n",
      "UP_std_hour: 698\n",
      "department_id: 664\n",
      "times_reordered_next_order: 651\n",
      "times_candidate: 649\n",
      "n_orders_most_frequent_day: 640\n",
      "UP_prob_reordered_next_order: 545\n",
      "UP_most_common_day_of_week: 473\n",
      "times_candidate_next_order: 401\n",
      "UP_orders: 339\n",
      "UP_times_reordered_next_order: 306\n",
      "UP_times_candidate_next_order: 238\n",
      "UP_reorder_rate: 181\n",
      "UP_proportion_occurences_most_common_day_of_week: 164\n",
      "prop_orders_most_frequent_day: 149\n",
      "same_day_most_common_day: 131\n",
      "UP_same_day_most_common_day: 95\n",
      "UP_occurences_most_common_day_of_week: 85\n",
      "times_reordered: 80\n",
      "UP_times_reordered: 79\n",
      "n_orders_most_frequent_day: 73\n",
      "same_day_last_order_day: 65\n",
      "UP_same_day_last_order: 63\n",
      "prob_purchase: 60\n",
      "same_day_most_common_day: 16\n",
      "same_day_last_order_day: 9\n",
      "UP_only_one_order: 0\n"
     ]
    }
   ],
   "source": [
    "# print feature importance\n",
    "idx_features= np.arange(d_train.num_feature())\n",
    "sorted_importance, sorted_idx = zip(*sorted(zip(bst.feature_importance(), idx_features), reverse=True))\n",
    "for i in range(len(sorted_idx)):\n",
    "    idx_feature = sorted_idx[i]\n",
    "    print(str(f_to_use[idx_feature]) + ': ' + str(sorted_importance[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'}, #'auc'\n",
    "    'num_leaves': 96,\n",
    "    'min_data_in_leaf': 100,\n",
    "    #'learning_rate': 0.1,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "\n",
    "final_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'}, #'auc'\n",
    "    'num_leaves': 96,\n",
    "    'min_data_in_leaf': 120,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.225\n",
      "f1 score: 0.452420991592\n",
      "accuracy: 0.881145374449\n"
     ]
    }
   ],
   "source": [
    "# TODO: We could improve this with the real F1-score\n",
    "\n",
    "# Tune threshold using validation set - Accuracy? f1_score? Do it individually per user and then compute mean?\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "thresholds = [0.15, 0.17, 0.19, 0.21, 0.22, 0.225, 0.23, 0.235, 0.24, 0.25, 0.27, 0.29]\n",
    "preds = bst.predict(df_val[f_to_use])\n",
    "acc_list = []\n",
    "f1_list = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred= preds > threshold\n",
    "    acc_list.append(accuracy_score(df_val['labels'].values, y_pred))\n",
    "    f1_list.append(f1_score(df_val['labels'].values, y_pred))\n",
    "\n",
    "pos_max = f1_list.index(max(f1_list))\n",
    "print('Best threshold: ' + str(thresholds[pos_max]))\n",
    "print('f1 score: ' + str(f1_list[pos_max]))\n",
    "print('accuracy: ' + str(acc_list[pos_max]))\n",
    "best_threshold = thresholds[pos_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilabel_fscore(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    ex1:\n",
    "    y_true = [1, 2, 3]\n",
    "    y_pred = [2, 3]\n",
    "    return: 0.8\n",
    "    \n",
    "    ex2:\n",
    "    y_true = [\"None\"]\n",
    "    y_pred = [2, \"None\"]\n",
    "    return: 0.666\n",
    "    \n",
    "    ex3:\n",
    "    y_true = [4, 5, 6, 7]\n",
    "    y_pred = [2, 4, 8, 9]\n",
    "    return: 0.25\n",
    "    \n",
    "    \"\"\"\n",
    "    y_true, y_pred = set(y_true), set(y_pred)\n",
    "    precision = sum([1 for i in y_pred if i in y_true]) / len(y_pred)\n",
    "    recall = sum([1 for i in y_true if i in y_pred]) / len(y_true)\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    return (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "thresholds = [0.15, 0.17, 0.19, 0.21, 0.23, 0.25, 0.27, 0.29]\n",
    "preds = bst.predict(df_val[f_to_use])\n",
    "df_val['pred'] = preds \n",
    "f1_list = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    f1_threshold = []\n",
    "    for order,group_order in df_val.groupby('order_id'):\n",
    "        y_true = group_order[group_order['labels'] == 1].product_id.values\n",
    "        if len(y_true) == 0:\n",
    "            y_true = [\"None\"]\n",
    "        y_pred = group_order[group_order['pred'] > threshold].product_id.values\n",
    "        if len(y_pred) == 0:\n",
    "            y_pred = [\"None\"]\n",
    "        f1_threshold.append(multilabel_fscore(y_true, y_pred))\n",
    "    f1_list.append(np.mean(f1_threshold))\n",
    "\n",
    "pos_max = f1_list.index(max(f1_list))\n",
    "print('Best threshold: ' + str(thresholds[pos_max]))\n",
    "print('f1 score: ' + str(f1_list[pos_max]))\n",
    "best_threshold = thresholds[pos_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# READ AGAIN THE DATA\n",
    "import pickle\n",
    "\n",
    "df_train = pd.read_csv('df_train.csv')\n",
    "\n",
    "with open(\"pickles/labels.pickle\", 'rb') as handle:\n",
    "    labels = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formating for lgb\n",
      "light GBM train :-)\n"
     ]
    }
   ],
   "source": [
    "# Train the final model with all the data\n",
    "    \n",
    "print('formating for lgb')\n",
    "d_train = lgb.Dataset(df_train[f_to_use],\n",
    "                      label=labels,\n",
    "                      categorical_feature=['aisle_id', 'department_id'])  # , 'order_hour_of_day', 'dow'\n",
    "final_ROUNDS = 340\n",
    "print('light GBM train :-)')\n",
    "bst = lgb.train(params=final_params, train_set=d_train, num_boost_round=final_ROUNDS, verbose_eval=10)\n",
    "bst.save_model('model.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_orders = pd.read_csv('../data/orders.csv', dtype={\n",
    "        'order_id': np.int32,\n",
    "        'user_id': np.int32,\n",
    "        'eval_set': 'object',\n",
    "        'order_number': np.int16,\n",
    "        'order_dow': np.int8,\n",
    "        'order_hour_of_day': np.int8,\n",
    "        'days_since_prior_order': np.float32})\n",
    "df_orders.set_index('order_id', inplace=True, drop=False)\n",
    "\n",
    "df_test_orders = df_orders[df_orders.eval_set == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_test = pd.read_csv('df_test.csv')\n",
    "    \n",
    "df_test['order_id'] = df_test['order_id'].astype(np.int32)\n",
    "df_test['product_id'] = df_test['product_id'].astype(np.int32)\n",
    "df_test['user_total_orders'] = df_test['user_total_orders'].astype(np.int16)\n",
    "df_test['user_total_items'] = df_test['user_total_items'].astype(np.int16)\n",
    "df_test['total_distinct_items'] = df_test['total_distinct_items'].astype(np.int16)\n",
    "df_test['user_average_days_between_orders'] = df_test['user_average_days_between_orders'].astype(np.float32)\n",
    "df_test['user_average_basket'] = df_test['user_average_basket'].astype(np.float32)\n",
    "df_test['mean_hour_purchase'] = df_test['mean_hour_purchase'].astype(np.float32)\n",
    "df_test['median_hour_purchase'] = df_test['median_hour_purchase'].astype(np.float32)\n",
    "df_test['most_frequent_day'] = df_test['most_frequent_day'].astype(np.int8)\n",
    "df_test['n_orders_most_frequent_day'] = df_test['n_orders_most_frequent_day'].astype(np.int16)\n",
    "df_test['prop_orders_most_frequent_day'] = df_test['prop_orders_most_frequent_day'].astype(np.float32)\n",
    "df_test['dow_last_prior_purchase'] = df_test['dow_last_prior_purchase'].astype(np.int8)\n",
    "df_test['order_dow'] = df_test['order_dow'].astype(np.int8)\n",
    "df_test['order_hour_of_day'] = df_test['order_hour_of_day'].astype(np.int8)\n",
    "df_test['days_since_prior_order'] = df_test['days_since_prior_order'].astype(np.float32)\n",
    "df_test['days_since_ratio'] = df_test['days_since_ratio'].astype(np.float32)\n",
    "df_test['delta_hour_vs_average'] = df_test['delta_hour_vs_average'].astype(np.float32)\n",
    "df_test['same_day_most_common_day'] = df_test['same_day_most_common_day'].astype(np.bool_)\n",
    "df_test['same_day_last_order_day'] = df_test['same_day_last_order_day'].astype(np.bool_)\n",
    "df_test['current_day'] = df_test['current_day'].astype(np.int16)\n",
    "df_test['aisle_id'] = df_test['aisle_id'].astype(np.uint8)\n",
    "df_test['department_id'] = df_test['department_id'].astype(np.uint8)\n",
    "df_test['product_orders'] = df_test['product_orders'].astype(np.int32)\n",
    "df_test['product_reorders'] = df_test['product_reorders'].astype(np.float32)\n",
    "df_test['product_reorder_rate'] = df_test['product_reorder_rate'].astype(np.float32)\n",
    "df_test['prob_purchase'] = df_test['prob_purchase'].astype(np.float32)\n",
    "df_test['aisle_orders'] = df_test['aisle_orders'].astype(np.int32)\n",
    "df_test['aisle_reorders'] = df_test['aisle_reorders'].astype(np.int32)\n",
    "df_test['aisle_reorder_rate'] = df_test['aisle_reorder_rate'].astype(np.float32)\n",
    "df_test['aisle_prob_purchase'] = df_test['aisle_prob_purchase'].astype(np.float32)\n",
    "df_test['department_orders'] = df_test['department_orders'].astype(np.int32)\n",
    "df_test['department_reorders'] = df_test['department_orders'].astype(np.int32)\n",
    "df_test['department_reorder_rate'] = df_test['department_reorder_rate'].astype(np.float32)\n",
    "df_test['department_prob_purchase'] = df_test['department_prob_purchase'].astype(np.float32)\n",
    "df_test['UP_orders'] = df_test['UP_orders'].astype(np.int16)\n",
    "df_test['UP_orders_ratio'] = df_test['UP_orders_ratio'].astype(np.float32)\n",
    "df_test['UP_average_pos_in_cart'] = df_test['UP_average_pos_in_cart'].astype(np.float32)\n",
    "df_test['UP_reorder_rate'] = df_test['UP_reorder_rate'].astype(np.float32)\n",
    "df_test['UP_orders_since_last'] = df_test['UP_orders_since_last'].astype(np.int16)\n",
    "df_test['UP_delta_hour_vs_last'] = df_test['UP_delta_hour_vs_last'].astype(np.int8)\n",
    "df_test['UP_mean_freq_days_order'] = df_test['UP_mean_freq_days_order'].astype(np.float32)\n",
    "df_test['UP_median_freq_days_order'] = df_test['UP_median_freq_days_order'].astype(np.float32)\n",
    "df_test['UP_only_one_order'] = df_test['UP_only_one_order'].astype(np.bool_)\n",
    "df_test['UP_days_from_last_purchase'] = df_test['UP_days_from_last_purchase'].astype(np.int16)\n",
    "df_test['UP_difference_last_purchase_and_mean'] = df_test['UP_difference_last_purchase_and_mean'].astype(np.float32)\n",
    "df_test['UP_days_from_last_purchase_ratio'] = df_test['UP_days_from_last_purchase_ratio'].astype(np.float32)\n",
    "df_test['UP_mean_hours'] = df_test['UP_mean_hours'].astype(np.float32)\n",
    "df_test['UP_delta_hour_vs_average_hour'] = df_test['UP_delta_hour_vs_average_hour'].astype(np.float32)\n",
    "df_test['UP_std_hour'] = df_test['UP_std_hour'].astype(np.float32)\n",
    "df_test['UP_most_common_day_of_week'] = df_test['UP_most_common_day_of_week'].astype(np.int8)\n",
    "df_test['UP_occurences_most_common_day_of_week'] = df_test['UP_occurences_most_common_day_of_week'].astype(np.int8)\n",
    "df_test['UP_proportion_occurences_most_common_day_of_week'] = df_test['UP_proportion_occurences_most_common_day_of_week'].astype(np.float32)\n",
    "df_test['UP_same_day_most_common_day'] = df_test['UP_same_day_most_common_day'].astype(np.bool_)\n",
    "df_test['UP_day_of_week_last_order'] = df_test['UP_day_of_week_last_order'].astype(np.int8)\n",
    "df_test['UP_same_day_last_order'] = df_test['UP_same_day_last_order'].astype(np.bool_)\n",
    "\n",
    "df_test['times_candidate'] = df_test['times_candidate'].astype(np.int32)\n",
    "df_test['times_reordered'] = df_test['times_reordered'].astype(np.int32)\n",
    "df_test['times_candidate_next_order'] = df_test['times_candidate_next_order'].astype(np.int32)\n",
    "df_test['times_reordered_next_order'] = df_test['times_reordered_next_order'].astype(np.int32)\n",
    "df_test['prob_reordered_candidate'] = (df_test['times_reordered']/df_test['times_candidate']).astype(np.float32)\n",
    "df_test['prob_reordered_next_order'] = (df_test['times_reordered_next_order']/df_test['times_candidate_next_order']).astype(np.float32)\n",
    "\n",
    "\n",
    "df_test['UP_times_candidate'] = df_test['UP_times_candidate'].astype(np.int32)\n",
    "df_test['UP_times_reordered'] = df_test['UP_times_reordered'].astype(np.int32)\n",
    "df_test['UP_times_candidate_next_order'] = df_test['UP_times_candidate_next_order'].astype(np.int32)\n",
    "df_test['UP_times_reordered_next_order'] = df_test['UP_times_reordered_next_order'].astype(np.int32)\n",
    "df_test['UP_prob_reordered_candidate'] = (df_test['UP_times_reordered']/df_test['UP_times_candidate']).astype(np.float32)\n",
    "df_test['UP_prob_reordered_next_order'] = (df_test['UP_times_reordered_next_order']/df_test['UP_times_candidate_next_order']).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light GBM predict\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('light GBM predict')\n",
    "preds = bst.predict(df_test[f_to_use])\n",
    "\n",
    "df_test['pred'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to_csv('df_test_with_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.225\n"
     ]
    }
   ],
   "source": [
    "TRESHOLD = best_threshold  \n",
    "print(TRESHOLD)\n",
    "d = dict()\n",
    "for row in df_test.itertuples():\n",
    "    if row.pred > TRESHOLD:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "\n",
    "for order in df_test_orders.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n",
    "\n",
    "sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "\n",
    "sub.reset_index(inplace=True)\n",
    "sub.columns = ['order_id', 'products']\n",
    "sub.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_threshold = 0.235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test_preds = df_test[['order_id', 'product_id', 'pred']]\n",
    "df_test_preds.to_csv('df_test_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light GBM predict train\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d30baa13cca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'light GBM predict train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf_to_use\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, data_has_header, is_reshape, pred_parameter)\u001b[0m\n\u001b[1;32m   1614\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m             \u001b[0mnum_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1616\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_has_header\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_reshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_to_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_parameter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot use Dataset instance for prediction, please use raw data instead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_data_from_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mpredict_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC_API_PREDICT_NORMAL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\"DataFrame.dtypes for data must be int, float or bool. Did not expect the data types in fields \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print('light GBM predict train')\n",
    "preds = bst.predict(df_train[f_to_use])\n",
    "\n",
    "df_train['pred'] = preds\n",
    "df_train_preds = df_train[['order_id', 'product_id', 'pred']]\n",
    "df_train_preds.to_csv('df_train_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_test_preds\n",
    "del df_test\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
